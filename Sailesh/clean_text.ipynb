{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_1_df = pd.read_csv(\"./Gujarat_samachar/gujaratsamachar_text1.csv\", delimiter=',')\n",
    "src_2_df = pd.read_csv(\"./IndianExpress/indianexpress_text.csv\", delimiter=',')\n",
    "src_3_df = pd.read_csv(\"./Oneindia/oneindia_text.csv\", delimiter=',')\n",
    "#src_4_df = pd.read_csv(\"./Corpus/Text_data.csv\", delimiter=',')\n",
    "src_5_df = pd.read_csv(\"./Westerntimes_news/westerntimesnews_text.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_personal_info(text):\n",
    "\n",
    "    phone_pattern = r'\\b(\\+?\\d{1,3}[-.\\s]?)?(\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{3,4}\\b'\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n",
    "\n",
    "    phone_numbers = re.findall(phone_pattern, text)\n",
    "    emails = re.findall(email_pattern, text)\n",
    "\n",
    "    if (len(phone_numbers) != 0) or (len(emails) != 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def detect_gujarati_slangs(text):\n",
    "\n",
    "    slangs = [\"માધારછોડ\", \"ગાંડુ\", \"રંડી\", \"બેટીચોડ\", \"ભોસડીકે\", \"ચુતીયા\", \"જણાતું\", \"ચૂત\", \"લૉડ\"]\n",
    "\n",
    "    slang_pattern = r'\\b(?:' + '|'.join(map(re.escape, slangs)) + r')\\b'\n",
    "    \n",
    "    slang_matches = re.findall(slang_pattern, text)\n",
    "    \n",
    "    if slang_matches:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def remove_special_char(text):\n",
    "    cleaned_text = re.sub(r'[\\\\//!@#$%^&*(),-?\":{}|<>]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_eng_char(text):\n",
    "    cleaned_text = re.sub(r'[A-Za-z]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_space(text):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def guj_eng_ratio(text):\n",
    "\n",
    "    english_pattern = r'[A-Za-z]'\n",
    "    \n",
    "    gujarati_pattern = r'[\\u0A80-\\u0AFF]'\n",
    "    \n",
    "    english_chars = re.findall(english_pattern, text)\n",
    "    gujarati_chars = re.findall(gujarati_pattern, text)\n",
    "    \n",
    "    num_english = len(english_chars)\n",
    "    num_gujarati = len(gujarati_chars)\n",
    "    \n",
    "    if num_gujarati > 0:\n",
    "        ratio = num_english / num_gujarati\n",
    "    else:\n",
    "        ratio = None\n",
    "    \n",
    "    return ratio    \n",
    "\n",
    "def gujarati_special_ratio(text):\n",
    "\n",
    "    gujarati_pattern = r'[\\u0A80-\\u0AFF]'\n",
    "    \n",
    "    special_pattern = r'[\\\\//!@#$%^&*(),.?\":{}|<>]'\n",
    "    \n",
    "    gujarati_chars = re.findall(gujarati_pattern, text)\n",
    "    special_chars = re.findall(special_pattern, text)\n",
    "    \n",
    "    num_gujarati = len(gujarati_chars)\n",
    "    num_special = len(special_chars)\n",
    "    \n",
    "    if num_gujarati > 0:\n",
    "        ratio = num_special / num_gujarati \n",
    "    else:\n",
    "        ratio = None\n",
    "    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_text(data_frame, batch_size=1000):\n",
    "\n",
    "    def process_sentence(sent):\n",
    "        ger = guj_eng_ratio(sent)\n",
    "        gsr = gujarati_special_ratio(sent)\n",
    "        \n",
    "        if (ger is None) or (gsr is None):\n",
    "            return None\n",
    "        if detect_gujarati_slangs(sent):\n",
    "            return None\n",
    "        if detect_personal_info(sent):\n",
    "            return None\n",
    "        if len(sent)<10:\n",
    "            return None\n",
    "        \n",
    "        return remove_special_char(remove_eng_char(remove_space(sent)))\n",
    "\n",
    "    def process_batch(batch):\n",
    "\n",
    "        batch['Text'] = batch['Text'].fillna('')\n",
    "        \n",
    "        #batch['Text'] = batch['Text'].str.split(\"', '\").apply(lambda para: \n",
    "        #    '\\n'.join(filter(None, [process_sentence(sent) for sent in para])))\n",
    "\n",
    "        batch['Text'] = batch['Text'].str.split(\"\\n\").apply(lambda para: \n",
    "            '\\n'.join(filter(None, [process_sentence(sent) for sent in para])))\n",
    "        \n",
    "        batch = batch[batch['Text'].str.strip() != '']\n",
    "        return batch\n",
    "\n",
    "    n = len(data_frame)\n",
    "    results = []\n",
    "    for start in range(0, n, batch_size):\n",
    "        batch = data_frame.iloc[start:start + batch_size].copy()\n",
    "        processed_batch = process_batch(batch)\n",
    "        results.append(processed_batch)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_1_df = preprocess_text(src_1_df, batch_size=5000)\n",
    "src_2_df = preprocess_text(src_2_df, batch_size=5000)\n",
    "src_3_df = preprocess_text(src_3_df, batch_size=5000)\n",
    "#src_4_df = preprocess_text(src_4_df, batch_size=5000)\n",
    "src_5_df = preprocess_text(src_5_df, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_1_df.to_csv(\"./Gujarat_samachar/gujaratsamachar_text1.csv\", index=False)\n",
    "src_2_df.to_csv(\"./IndianExpress/indianexpress_text.csv\", index=False)\n",
    "src_3_df.to_csv(\"./Oneindia/oneindia_text.csv\", index=False)\n",
    "#src_4_df.to_csv(\"./Corpus/corpus_text.csv\", index=False)\n",
    "src_5_df.to_csv(\"./Westerntimes_news/westerntimesnews_text.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
